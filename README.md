---
output:
  pdf_document: default
  html_document: default
---
# ğŸ“‹ Logbuch Analyzer

Eine intelligente Anwendung zur semantischen Suche und KI-gestÃ¼tzten Analyse von handschriftlichen Logbuch-EintrÃ¤gen.

## ğŸš€ Features

- **ğŸ§  Intelligente Ergebnisoptimierung**: Automatische Bestimmung der optimalen Anzahl Suchergebnisse
- **ğŸ¤– Integrierte KI-Analyse**: Vollautomatische LLM-Integration fÃ¼r detaillierte Auswertungen
- **âš¡ Auto-Initialisierung**: Embedding-Modell und Ollama-Status werden beim Start automatisch geprÃ¼ft
- **ğŸ“Š Live System-Monitoring**: Terminal-Ausgaben und System-Status direkt in der App
- **ğŸ” Semantische Suche**: Findet relevante EintrÃ¤ge auch bei ungenauen Suchbegriffen
- **ğŸ“ˆ Relevanz-basierte Anzeige**: Farbkodierte Ergebnisse nach Relevanz-Score
- **ğŸ“Š Flexible CSV-UnterstÃ¼tzung**: Komma, Semikolon, Leerzeichen als Trennzeichen
- **ğŸ”’ 100% Lokal**: Keine Cloud-Services, Ihre Daten bleiben bei Ihnen
- **ğŸ¯ Logbuch-optimiert**: Speziell fÃ¼r Struktur: Datum, Zeit, Lot-Nr., Subsystem, Ereignis & MaÃŸnahme, Visum

---

## ğŸ“¦ Installation

### Schritt 1: Repository klonen/downloaden

```bash
# Arbeitsverzeichnis erstellen
mkdir logbuch-analyzer
cd logbuch-analyzer

# Dateien herunterladen:
# - logbook_analyzer.py
# - start_app.py  
# - requirements.txt
```

### Schritt 2: Python Virtual Environment

```bash
# Virtual Environment erstellen
python -m venv logbook_env

# Aktivieren
# Windows:
logbook_env\Scripts\activate

# Linux/Mac:
source logbook_env/bin/activate
```

### Schritt 3: Python Dependencies installieren

```bash
# Requirements installieren
pip install -r requirements.txt

# Bei Problemen: pip upgrade
pip install --upgrade pip
pip install -r requirements.txt
```

---

## ğŸ¦™ Ollama Installation & Setup

### Schritt 1: Ollama herunterladen

**Website:** https://ollama.ai

**Direkte Downloads:**
- **Windows**: https://ollama.ai/download/windows
- **Mac**: https://ollama.ai/download/mac  
- **Linux**: 
  ```bash
  curl -fsSL https://ollama.ai/install.sh | sh
  ```

### Schritt 2: Ollama installieren

- **Windows**: `.exe` Datei ausfÃ¼hren und Installationsanweisungen folgen
- **Mac**: `.dmg` Datei Ã¶ffnen und in Applications ziehen
- **Linux**: Automatische Installation Ã¼ber Curl-Befehl

### Schritt 3: Ollama Server starten

```bash
# Ollama Server starten (Terminal/CMD offen lassen)
ollama serve
```

**âœ… Erfolg**: Sie sollten sehen: `Ollama server starting...`

### Schritt 4: Modell herunterladen

```bash
# Neues Terminal/CMD-Fenster Ã¶ffnen
# Empfohlenes Modell (Deutsch-optimiert):
ollama pull llama3.1:8b

# Alternative kleinere Modelle (schneller, weniger RAM):
ollama pull llama3.2:3b
ollama pull mistral:7b

# VerfÃ¼gbare Modelle anzeigen:
ollama list
```

**â±ï¸ Dauer**: 5-15 Minuten je nach Internetverbindung

### Schritt 5: Ollama testen

```bash
# Test-Chat
ollama run llama3.1:8b "Hallo, kannst du mir auf Deutsch antworten?"

# Erwartete Antwort: Deutsche BegrÃ¼ÃŸung
# Mit Ctrl+C beenden
```

---

## ğŸƒâ€â™‚ï¸ App starten

### Methode 1: Optimierter Starter (empfohlen)

```bash
# Stelle sicher, dass Virtual Environment aktiv ist
# Arbeitsverzeichnis: logbuch-analyzer/

python start_app.py
```

### Methode 2: Direkter Start

```bash
streamlit run logbook_analyzer.py --server.fileWatcherType none --logger.level error
```

### Methode 3: Einfacher Start

```bash
streamlit run logbook_analyzer.py
```

**ğŸŒ App Ã¶ffnet sich automatisch im Browser:** http://localhost:8501

---

## ğŸ“‹ Erste Schritte

### 1. **Automatische Initialisierung**
- App startet sich selbst und lÃ¤dt alle Komponenten
- System-Status wird in der Sidebar angezeigt
- Ollama-Verbindung wird automatisch getestet

### 2. **CSV-Datei hochladen**
- Hauptbereich â†’ "CSV-Datei hochladen"
- UnterstÃ¼tzte Formate: `.csv` mit beliebigen Trennzeichen
- Automatische Erkennung von Encoding und Separatoren

**Erwartete Spalten:**
- Datum
- Zeit  
- Lot-Nr.
- Subsystem
- Ereignis & MaÃŸnahme
- Visum

### 3. **Daten verarbeiten**
- "ğŸ”„ Daten verarbeiten" klicken
- Automatische Embedding-Erstellung
- System bereit fÃ¼r intelligente Suche

### 4. **Intelligente Suche nutzen**
- NatÃ¼rlichsprachliche Anfragen stellen
- **Automatische Ergebnisoptimierung**: System bestimmt beste Anzahl Ergebnisse
- **Integrierte KI-Analyse**: Detaillierte Auswertung wird automatisch erstellt
- Beispiel-Queries:
  ```
  Probleme mit Lot 12345
  Temperaturprobleme in der Heizung
  Alle EintrÃ¤ge von System XY letzte Woche
  Wann gab es AusfÃ¤lle im Ventilsystem?
  ```

### 5. **System-Monitoring**
- Sidebar zeigt Live-Status aller Komponenten
- Terminal-Logs werden direkt in der App angezeigt
- Automatische Ollama-StatusprÃ¼fung

---

## ğŸ”§ Fehlerbehebung

### âŒ "Ollama Server nicht erreichbar"

**LÃ¶sung:**
```bash
# 1. PrÃ¼fen ob Ollama lÃ¤uft
curl http://localhost:11434/api/tags

# 2. Falls Fehler, Ollama neu starten
ollama serve

# 3. Modell prÃ¼fen
ollama list
```

### âŒ "CSV konnte nicht gelesen werden"

**LÃ¶sung:**
- PrÃ¼fen Sie Trennzeichen (Komma, Semikolon)
- Encoding Ã¤ndern (UTF-8 â†’ Latin1)
- Spaltenheader Ã¼berprÃ¼fen

### âŒ "Embedding-Modell Fehler"

**LÃ¶sung:**
```bash
# Internet-Verbindung prÃ¼fen
pip install --upgrade sentence-transformers

# Bei RAM-Problemen kleineres Modell verwenden
# Modell-Name in Code Ã¤ndern: 'all-MiniLM-L6-v2'
```

### âŒ Python/Pip Probleme

**LÃ¶sung:**
```bash
# Python Version prÃ¼fen (>=3.8)
python --version

# Pip upgraden
pip install --upgrade pip

# Virtual Environment neu erstellen
deactivate
rm -rf logbook_env
python -m venv logbook_env
```

---

## ğŸ’¡ Tipps & Tricks

### **Ohne LLM verwenden**
- Sidebar â†’ "LLM-Analyse verwenden" deaktivieren
- Semantische Suche funktioniert auch ohne Ollama

### **Performance optimieren**
- Kleineres Modell: `ollama pull llama3.2:3b`
- Weniger Suchergebnisse: Slider auf 5-10 setzen
- Starke Hardware: `llama3.1:70b` fÃ¼r beste QualitÃ¤t

### **CSV-Format optimieren**
```csv
Datum,Zeit,Lot-Nr.,Subsystem,Ereignis & Massnahme,Visum
2024-01-15,14:30,LOT-001,Pumpe,Druckabfall erkannt - Ventil gereinigt,MK
2024-01-15,15:45,LOT-002,Heizung,Temperatur zu niedrig - Thermostat justiert,AB
```

### **Beispiel-Searches**
```
NatÃ¼rlichsprachlich:
- "Zeige mir alle Probleme mit Lot 12345"
- "Wann gab es Temperaturprobleme?"
- "Alle EintrÃ¤ge von Benutzer MK"

Stichwort-basiert:
- "Druckabfall Pumpe"
- "Heizung Ausfall"
- "QualitÃ¤t Problem"
```

---

## ğŸ“Š Systemanforderungen

### **Minimum:**
- Python 3.8+
- 4 GB RAM
- 2 GB freier Speicher
- Internet (initial fÃ¼r Downloads)

### **Empfohlen:**
- Python 3.10+
- 8 GB RAM  
- 5 GB freier Speicher
- GPU (optional, fÃ¼r bessere Performance)

---

## ğŸ†˜ Support

### **HÃ¤ufige Probleme:**
1. **Ollama Status prÃ¼fen**: http://localhost:11434
2. **Logs ansehen**: Terminal-Ausgabe beachten
3. **Virtual Environment**: Immer aktiviert lassen
4. **Firewall**: Port 11434 freigeben

### **Bei weiteren Problemen:**
- Detaillierte Fehlermeldung kopieren
- Python Version und OS angeben
- Screenshots des Fehlers

---

## ğŸ“ Dateistruktur

```
logbuch-analyzer/
â”œâ”€â”€ logbook_analyzer.py    # Hauptanwendung
â”œâ”€â”€ start_app.py          # Optimierter Starter
â”œâ”€â”€ requirements.txt      # Python Dependencies
â”œâ”€â”€ README.md            # Diese Anleitung
â””â”€â”€ logbook_env/         # Virtual Environment (nach Setup)
```

---

## âš–ï¸ Lizenz & Datenschutz

- **100% lokal**: Keine Daten verlassen Ihren Computer
- **Open Source**: Frei verwendbar und anpassbar
- **Keine Telemetrie**: Keine Datensammlung

---

**ğŸ‰ Viel Erfolg mit Ihrem Logbuch Analyzer!**